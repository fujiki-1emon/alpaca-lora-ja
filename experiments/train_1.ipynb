{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba598f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mdatasets                      2.11.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0msentencepiece                 0.1.96\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mtransformers                  4.28.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mtqdm                          4.65.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep datasets\n",
    "!pip list | grep sentencepiece\n",
    "!pip list | grep transformers\n",
    "!pip list | grep tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79a732b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install bitsandbytes\n",
    "# !pip install loralib\n",
    "# !pip install -q git+https://github.com/huggingface/peft.git\n",
    "# !pip install --upgrade accelerate\n",
    "# !pip install -U tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57833a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda110_nocublaslt.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 110\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda110_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import bitsandbytes as bnb\n",
    "from datasets import load_dataset\n",
    "import transformers as T\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from peft import prepare_model_for_int8_training, LoraConfig, get_peft_model, get_peft_model_state_dict\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67261d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MICRO_BATCH_SIZE = 4\n",
    "BATCH_SIZE = 128\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "EPOCHS = 3 \n",
    "LEARNING_RATE = 3e-4\n",
    "CUTOFF_LEN = 256\n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.05\n",
    "VAL_SET_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaba20de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405045df8cd7406dbca4f3d3c919af15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"decapoda-research/llama-7b-hf\",\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a27fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    \"decapoda-research/llama-7b-hf\", add_eos_token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e85b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_int8_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1574cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "tokenizer.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a23f74b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-88fb7e0d1f58050f/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83aa7b5085674b109b6a9dfe971d5316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5345c73c71ad479b93fc99113a83eac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-88fb7e0d1f58050f/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2869c7e73f49c19b131b1260013c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=\"japanese_alpaca_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ddfaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = data[\"train\"].train_test_split(\n",
    "    test_size=VAL_SET_SIZE, shuffle=True, seed=42\n",
    ")\n",
    "train_data = train_val[\"train\"]\n",
    "val_data = train_val[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b03982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    # sorry about the formatting disaster gotta move fast\n",
    "    if data_point[\"input\"]:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\"\n",
    "    \n",
    "def tokenize(prompt):\n",
    "    # there's probably a way to do this with the tokenizer settings\n",
    "    # but again, gotta move fast\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=CUTOFF_LEN + 1,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": result[\"input_ids\"][:-1],\n",
    "        \"attention_mask\": result[\"attention_mask\"][:-1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04d8cb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data.shuffle().map(lambda x: tokenize(generate_prompt(x)))\n",
    "val_data = val_data.shuffle().map(lambda x: tokenize(generate_prompt(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efaaba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
    "ddp = world_size != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b04dc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9713ac4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1146</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_module</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1143 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1144 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_module</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module_name: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1145 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1146 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> importlib.import_module(<span style=\"color: #808000; text-decoration-color: #808000\">\".\"</span> + module_name, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1147 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1148 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1149 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Failed to import {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}.{</span>module_name<span style=\"color: #808000; text-decoration-color: #808000\">} because of the followin</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/importlib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">127</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">import_module</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> character != <span style=\"color: #808000; text-decoration-color: #808000\">'.'</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 │   │   │   </span>level += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>127 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _bootstrap._gcd_import(name[level:], package, level)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130 </span>_RELOADING = {}                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_gcd_import</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_find_and_load</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_find_and_load_unlocked</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_unlocked</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">exec_module</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_with_frames_removed</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">173</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 170 │   </span>DEFAULT_PROGRESS_CALLBACK = NotebookProgressCallback                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 171 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 172 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_apex_available():                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 173 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">apex</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> amp                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 174 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 175 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_datasets_available():                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 176 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">datasets</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ImportError: </span>cannot import name <span style=\"color: #008000; text-decoration-color: #008000\">'amp'</span> from <span style=\"color: #008000; text-decoration-color: #008000\">'apex'</span> <span style=\"font-weight: bold\">(</span>unknown location<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "<span style=\"font-style: italic\">The above exception was the direct cause of the following exception:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 1 trainer = T.Trainer(                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 │   </span>model=model,                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 │   </span>train_dataset=train_data,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 │   </span>eval_dataset=val_data,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1136</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._modules:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1134 │   │   │   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_module(name)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1135 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._class_to_module.keys():                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1136 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._class_to_module[name])                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1137 │   │   │   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(module, name)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1138 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1139 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AttributeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"module {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">} has no attribute {</span>name<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">import_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1148</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_module</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1145 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1146 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> importlib.import_module(<span style=\"color: #808000; text-decoration-color: #808000\">\".\"</span> + module_name, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1147 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1148 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1149 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Failed to import {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}.{</span>module_name<span style=\"color: #808000; text-decoration-color: #808000\">} because of the followin</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1150 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" traceback):\\n{</span>e<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1151 │   │   │   </span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">e</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Failed to import transformers.trainer because of the following error <span style=\"font-weight: bold\">(</span>look up to see its traceback<span style=\"font-weight: bold\">)</span>:\n",
       "cannot import name <span style=\"color: #008000; text-decoration-color: #008000\">'amp'</span> from <span style=\"color: #008000; text-decoration-color: #008000\">'apex'</span> <span style=\"font-weight: bold\">(</span>unknown location<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1146\u001b[0m in \u001b[92m_get_module\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1143 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1144 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_module\u001b[0m(\u001b[96mself\u001b[0m, module_name: \u001b[96mstr\u001b[0m):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1145 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1146 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m importlib.import_module(\u001b[33m\"\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m + module_name, \u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1147 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1148 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1149 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFailed to import \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m{\u001b[0mmodule_name\u001b[33m}\u001b[0m\u001b[33m because of the followin\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/importlib/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m127\u001b[0m in \u001b[92mimport_module\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m character != \u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m'\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m126 \u001b[0m\u001b[2m│   │   │   \u001b[0mlevel += \u001b[94m1\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m127 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _bootstrap._gcd_import(name[level:], package, level)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m_RELOADING = {}                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_gcd_import\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_find_and_load\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_find_and_load_unlocked\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_load_unlocked\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mexec_module\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_call_with_frames_removed\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m173\u001b[0m in \u001b[92m<module>\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 170 \u001b[0m\u001b[2m│   \u001b[0mDEFAULT_PROGRESS_CALLBACK = NotebookProgressCallback                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 171 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 172 \u001b[0m\u001b[94mif\u001b[0m is_apex_available():                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 173 \u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mapex\u001b[0m \u001b[94mimport\u001b[0m amp                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 174 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 175 \u001b[0m\u001b[94mif\u001b[0m is_datasets_available():                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 176 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mdatasets\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mImportError: \u001b[0mcannot import name \u001b[32m'amp'\u001b[0m from \u001b[32m'apex'\u001b[0m \u001b[1m(\u001b[0munknown location\u001b[1m)\u001b[0m\n",
       "\n",
       "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 1 trainer = T.Trainer(                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[2m│   \u001b[0mmodel=model,                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   \u001b[0mtrain_dataset=train_data,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   \u001b[0meval_dataset=val_data,                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1136\u001b[0m in \u001b[92m__getattr__\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m name \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._modules:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1134 \u001b[0m\u001b[2m│   │   │   \u001b[0mvalue = \u001b[96mself\u001b[0m._get_module(name)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1135 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m name \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._class_to_module.keys():                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1136 \u001b[2m│   │   │   \u001b[0mmodule = \u001b[96mself\u001b[0m._get_module(\u001b[96mself\u001b[0m._class_to_module[name])                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1137 \u001b[0m\u001b[2m│   │   │   \u001b[0mvalue = \u001b[96mgetattr\u001b[0m(module, name)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1138 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1139 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAttributeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mmodule \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m has no attribute \u001b[0m\u001b[33m{\u001b[0mname\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/transformers/utils/\u001b[0m\u001b[1;33mimport_utils.py\u001b[0m:\u001b[94m1148\u001b[0m in \u001b[92m_get_module\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1145 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1146 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m importlib.import_module(\u001b[33m\"\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m + module_name, \u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1147 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1148 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1149 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFailed to import \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m{\u001b[0mmodule_name\u001b[33m}\u001b[0m\u001b[33m because of the followin\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1150 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m traceback):\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m{\u001b[0me\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1151 \u001b[0m\u001b[2m│   │   │   \u001b[0m) \u001b[94mfrom\u001b[0m \u001b[4;96me\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mFailed to import transformers.trainer because of the following error \u001b[1m(\u001b[0mlook up to see its traceback\u001b[1m)\u001b[0m:\n",
       "cannot import name \u001b[32m'amp'\u001b[0m from \u001b[32m'apex'\u001b[0m \u001b[1m(\u001b[0munknown location\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = T.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=T.TrainingArguments(\n",
    "        per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "        warmup_steps=100,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        fp16=True,\n",
    "        logging_steps=20,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=200,\n",
    "        save_steps=200,\n",
    "        output_dir=\"../outputs/japanese-lora-alpaca_train_1\",\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True,\n",
    "        ddp_find_unused_parameters=False if ddp else None,\n",
    "    ),\n",
    "    data_collator=T.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdf1ac92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fnakamura/workspace/apex\n",
      "Using pip 23.1.2 from /opt/conda/lib/python3.8/site-packages/pip (python 3.8)\n",
      "\u001b[33mDEPRECATION: --build-option and --global-option are deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use --config-settings. Discussion can be found at https://github.com/pypa/pip/issues/11859\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /home/fnakamura/workspace/apex\n",
      "  Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.13.1+cu117\n",
      "\n",
      "\n",
      "  running egg_info\n",
      "  creating /tmp/pip-pip-egg-info-h85js14d/apex.egg-info\n",
      "  writing /tmp/pip-pip-egg-info-h85js14d/apex.egg-info/PKG-INFO\n",
      "  writing dependency_links to /tmp/pip-pip-egg-info-h85js14d/apex.egg-info/dependency_links.txt\n",
      "  writing requirements to /tmp/pip-pip-egg-info-h85js14d/apex.egg-info/requires.txt\n",
      "  writing top-level names to /tmp/pip-pip-egg-info-h85js14d/apex.egg-info/top_level.txt\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-h85js14d/apex.egg-info/SOURCES.txt'\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-h85js14d/apex.egg-info/SOURCES.txt'\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: packaging>20.6 in /opt/conda/lib/python3.8/site-packages (from apex==0.1) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>20.6->apex==0.1) (2.4.2)\n",
      "Building wheels for collected packages: apex\n",
      "  Running command python setup.py bdist_wheel\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.13.1+cu117\n",
      "\n",
      "\n",
      "\n",
      "  Compiling cuda extensions with\n",
      "  nvcc: NVIDIA (R) Cuda compiler driver\n",
      "  Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "  Built on Wed_Jul_22_19:09:09_PDT_2020\n",
      "  Cuda compilation tools, release 11.0, V11.0.221\n",
      "  Build cuda_11.0_bu.TC445_37.28845127_0\n",
      "  from /usr/local/cuda/bin\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"/home/fnakamura/workspace/apex/setup.py\", line 178, in <module>\n",
      "      check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)\n",
      "    File \"/home/fnakamura/workspace/apex/setup.py\", line 33, in check_cuda_torch_binary_vs_bare_metal\n",
      "      raise RuntimeError(\n",
      "  RuntimeError: Cuda extensions are being compiled with a version of Cuda that does not match the version used to compile Pytorch binaries.  Pytorch binaries were compiled with Cuda 11.7.\n",
      "  In some cases, a minor-version mismatch will not cause later errors:  https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  You can try commenting out this check (at your own risk).\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[1;35mfull command\u001b[0m: \u001b[34m/opt/conda/bin/python -u -c '\u001b[0m\n",
      "\u001b[34m  exec(compile('\"'\"''\"'\"''\"'\"'\u001b[0m\n",
      "\u001b[34m  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
      "\u001b[34m  #\u001b[0m\n",
      "\u001b[34m  # - It imports setuptools before invoking setup.py, to enable projects that directly\u001b[0m\n",
      "\u001b[34m  #   import from `distutils.core` to work with newer packaging standards.\u001b[0m\n",
      "\u001b[34m  # - It provides a clear error message when setuptools is not installed.\u001b[0m\n",
      "\u001b[34m  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\u001b[0m\n",
      "\u001b[34m  #   setuptools doesn'\"'\"'t think the script is `-c`. This avoids the following warning:\u001b[0m\n",
      "\u001b[34m  #     manifest_maker: standard file '\"'\"'-c'\"'\"' not found\".\u001b[0m\n",
      "\u001b[34m  # - It generates a shim setup.py, for handling setup.cfg-only projects.\u001b[0m\n",
      "\u001b[34m  import os, sys, tokenize\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  try:\u001b[0m\n",
      "\u001b[34m      import setuptools\u001b[0m\n",
      "\u001b[34m  except ImportError as error:\u001b[0m\n",
      "\u001b[34m      print(\u001b[0m\n",
      "\u001b[34m          \"ERROR: Can not execute `setup.py` since setuptools is not available in \"\u001b[0m\n",
      "\u001b[34m          \"the build environment.\",\u001b[0m\n",
      "\u001b[34m          file=sys.stderr,\u001b[0m\n",
      "\u001b[34m      )\u001b[0m\n",
      "\u001b[34m      sys.exit(1)\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  __file__ = %r\u001b[0m\n",
      "\u001b[34m  sys.argv[0] = __file__\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  if os.path.exists(__file__):\u001b[0m\n",
      "\u001b[34m      filename = __file__\u001b[0m\n",
      "\u001b[34m      with tokenize.open(__file__) as f:\u001b[0m\n",
      "\u001b[34m          setup_py_code = f.read()\u001b[0m\n",
      "\u001b[34m  else:\u001b[0m\n",
      "\u001b[34m      filename = \"<auto-generated setuptools caller>\"\u001b[0m\n",
      "\u001b[34m      setup_py_code = \"from setuptools import setup; setup()\"\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  exec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
      "\u001b[34m  '\"'\"''\"'\"''\"'\"' % ('\"'\"'/home/fnakamura/workspace/apex/setup.py'\"'\"',), \"<pip-setuptools-caller>\", \"exec\"))' --cpp_ext --cuda_ext bdist_wheel -d /tmp/pip-wheel-184qpna2\u001b[0m\n",
      "  \u001b[1;35mcwd\u001b[0m: /home/fnakamura/workspace/apex/\n",
      "  Building wheel for apex (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Failed building wheel for apex\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for apex\n",
      "  Running command python setup.py clean\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.13.1+cu117\n",
      "\n",
      "\n",
      "\n",
      "  Compiling cuda extensions with\n",
      "  nvcc: NVIDIA (R) Cuda compiler driver\n",
      "  Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "  Built on Wed_Jul_22_19:09:09_PDT_2020\n",
      "  Cuda compilation tools, release 11.0, V11.0.221\n",
      "  Build cuda_11.0_bu.TC445_37.28845127_0\n",
      "  from /usr/local/cuda/bin\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"/home/fnakamura/workspace/apex/setup.py\", line 178, in <module>\n",
      "      check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)\n",
      "    File \"/home/fnakamura/workspace/apex/setup.py\", line 33, in check_cuda_torch_binary_vs_bare_metal\n",
      "      raise RuntimeError(\n",
      "  RuntimeError: Cuda extensions are being compiled with a version of Cuda that does not match the version used to compile Pytorch binaries.  Pytorch binaries were compiled with Cuda 11.7.\n",
      "  In some cases, a minor-version mismatch will not cause later errors:  https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  You can try commenting out this check (at your own risk).\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py clean\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[1;35mfull command\u001b[0m: \u001b[34m/opt/conda/bin/python -u -c '\u001b[0m\n",
      "\u001b[34m  exec(compile('\"'\"''\"'\"''\"'\"'\u001b[0m\n",
      "\u001b[34m  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
      "\u001b[34m  #\u001b[0m\n",
      "\u001b[34m  # - It imports setuptools before invoking setup.py, to enable projects that directly\u001b[0m\n",
      "\u001b[34m  #   import from `distutils.core` to work with newer packaging standards.\u001b[0m\n",
      "\u001b[34m  # - It provides a clear error message when setuptools is not installed.\u001b[0m\n",
      "\u001b[34m  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\u001b[0m\n",
      "\u001b[34m  #   setuptools doesn'\"'\"'t think the script is `-c`. This avoids the following warning:\u001b[0m\n",
      "\u001b[34m  #     manifest_maker: standard file '\"'\"'-c'\"'\"' not found\".\u001b[0m\n",
      "\u001b[34m  # - It generates a shim setup.py, for handling setup.cfg-only projects.\u001b[0m\n",
      "\u001b[34m  import os, sys, tokenize\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  try:\u001b[0m\n",
      "\u001b[34m      import setuptools\u001b[0m\n",
      "\u001b[34m  except ImportError as error:\u001b[0m\n",
      "\u001b[34m      print(\u001b[0m\n",
      "\u001b[34m          \"ERROR: Can not execute `setup.py` since setuptools is not available in \"\u001b[0m\n",
      "\u001b[34m          \"the build environment.\",\u001b[0m\n",
      "\u001b[34m          file=sys.stderr,\u001b[0m\n",
      "\u001b[34m      )\u001b[0m\n",
      "\u001b[34m      sys.exit(1)\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  __file__ = %r\u001b[0m\n",
      "\u001b[34m  sys.argv[0] = __file__\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  if os.path.exists(__file__):\u001b[0m\n",
      "\u001b[34m      filename = __file__\u001b[0m\n",
      "\u001b[34m      with tokenize.open(__file__) as f:\u001b[0m\n",
      "\u001b[34m          setup_py_code = f.read()\u001b[0m\n",
      "\u001b[34m  else:\u001b[0m\n",
      "\u001b[34m      filename = \"<auto-generated setuptools caller>\"\u001b[0m\n",
      "\u001b[34m      setup_py_code = \"from setuptools import setup; setup()\"\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  exec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
      "\u001b[34m  '\"'\"''\"'\"''\"'\"' % ('\"'\"'/home/fnakamura/workspace/apex/setup.py'\"'\"',), \"<pip-setuptools-caller>\", \"exec\"))' --cpp_ext --cuda_ext clean --all\u001b[0m\n",
      "  \u001b[1;35mcwd\u001b[0m: /home/fnakamura/workspace/apex\n",
      "\u001b[31m  ERROR: Failed cleaning build dir for apex\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build apex\n",
      "\u001b[31mERROR: Could not build wheels for apex, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc99e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b0b03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
